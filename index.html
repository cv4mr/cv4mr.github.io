<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="" />
    <meta name="author" content="" />

    <title>CV4MR 2025</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link href="css/agency.css" rel="stylesheet" />

    <!-- Custom Fonts -->
    <link
      href="font-awesome/css/font-awesome.min.css"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="http://fonts.googleapis.com/css?family=Montserrat:400,700"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="http://fonts.googleapis.com/css?family=Kaushan+Script"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="http://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700"
      rel="stylesheet"
      type="text/css"
    />

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body id="page-top" class="index">
    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
          <button
            type="button"
            class="navbar-toggle"
            data-toggle="collapse"
            data-target="#bs-example-navbar-collapse-1"
          >
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand page-scroll" href="#page-top">CV4MR</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li class="hidden">
              <a href="#page-top"></a>
            </li>
            <li>
              <a class="page-scroll" href="#overview">Overview</a>
            </li>
            <li>
              <a class="page-scroll" href="#program">Program</a>
            </li>
            <li>
              <a class="page-scroll" href="#speakers">Speakers</a>
            </li>
            <li>
              <a class="page-scroll" href="#call_for_papers">Call for Papers</a>
            </li>
            <li>
              <a class="page-scroll" href="#organizers">Organizers</a>
            </li>
            <li>
              <a class="page-scroll" href="#contact">Contact</a>
            </li>
          </ul>
        </div>
        <!-- /.navbar-collapse -->
      </div>
      <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
      <div class="container">
        <div class="intro-text">
          <div class="intro-lead-in">11 June, 2025, 8 AM - 12 PM üìç Room 109 @ Music City Center, Nashville, TN, US</div>
          <div class="intro-heading">
            Workshop on Computer Vision for Mixed Reality
          </div>
          <div class="intro-lead-out">In conjunction with CVPR 2025</div>
          <a href="#call_for_papers" class="page-scroll btn btn-xl"
            >Call for Papers</a
          >
        </div>
      </div>
    </header>

    <!-- Overview Section -->
    <section id="overview">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Overview</h2>
          </div>
          <div class="col-lg-12 text-left">
            Virtual Reality (VR) technologies have the potential to transform
            the way we use computing to interact with our environment, do our
            work and connect with each other. VR devices provide users with
            immersive experiences at the cost of blocking the visibility of the
            surrounding environment. With the advent of passthrough techniques
            such as those in Quest-3 and Apple Vision Pro, now users can build
            deeply immersive experiences which mix the virtual and the real
            world into one, often also called Mixed Reality (MR). MR poses a set
            of very unique research problems in computer vision that are not
            covered by VR. Our focus is on capturing the real environment around
            the user using cameras which are placed away from the user's eyes,
            yet reconstruct the environment with high fidelity, augmented the
            environment with virtual objects and effects, and all in real-time.
            We aim to offer the research community to deeply understand the
            unique challenges of Mixed Reality and research on novel methods
            encompassing View Synthesis, Scene Understanding, efficient
            On-Device AI among other things.
          </div>
        </div>
      </div>
    </section>

    <!-- Program Section -->
    <!-- <section id="program">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Program</h2>
          </div>
          <div class="col-lg-12 text-left">
            üìç Summit 332, Seattle Convention Center üì∫  <a href="https://youtu.be/mGrLCvQtUNs">Recording</a>
          </div>
          <div class="col-lg-12 text-left">
            <table
              style="width: 100%; border-collapse: collapse; margin-top: 10px"
            >
              <tr style="border-bottom: 1px solid #ccc"></tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>08:00-08:15 am</td>
                <td>
                  <a href="https://www.linkedin.com/in/rakesh-r-3848538/"
                    >Rakesh Ranjan</a
                  >
                </td>
                <td><b>Opening Remarks</b></td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>08:15-09:00 am</td>
                <td>
                  <a
                    href="https://scholar.google.com/citations?user=-qncsGYAAAAJ"
                    >Douglas Lanman</a
                  >
                </td>
                <td style="border: none; max-width: 650px">
                  <b>[Keynote] Taking a Small Step in a Different Direction</b>
                  <br />
                  The computer vision community has recently made rapid and
                  significant progress on the grand challenge of novel view
                  synthesis. New frameworks ‚Äî including multiplane images,
                  neural radiance fields, and Gaussian splatting ‚Äî may
                  ultimately provide the foundation for tomorrow‚Äôs volumetric
                  video systems. When viewed with emerging mixed reality (MR)
                  headsets, such frameworks may unlock fully immersive forms of
                  today‚Äôs television and film content. <br />
                  Yet, these emerging view synthesis frameworks do not fully
                  meet the needs of MR headsets. In addition to capturing and
                  viewing entire environments across broad viewpoint changes, MR
                  fundamentally needs computer vision systems that can also
                  reproject from headset-mounted sensors to the perspective of
                  the viewer‚Äôs eyes. In this talk, we aim to inspire a greater
                  focus in the computer vision community on developing view
                  synthesis algorithms that can achieve this ‚Äòsmall step‚Äô in
                  perspective with algorithms that may fundamentally differ from
                  emerging frameworks (due to the need to achieve this
                  transformation in real time, with limited computing resources,
                  and at a fidelity approaching that of human vision). <br />We
                  start with a systems-level view of this problem: examining
                  whether hardware modifications alone might eliminate the need
                  for real-time view reprojection for MR, based on recent
                  psychophysical studies determining the threshold of
                  detectability for perspective distortions. We‚Äôll also review
                  our latest progress on meeting this system-level challenge,
                  reviewing our ‚Äòneural passthrough‚Äô and ‚Äòreverse passthrough‚Äô
                  headset prototypes, as well as early demonstrations of mixed
                  reality stylization and editing systems that can be applied in
                  combination with real-time passthrough reprojection
                  algorithms. We conclude by looking towards the larger problems
                  in this space, including building volumetric capture and
                  real-time view synthesis methods that match the limits of
                  human perception, including the challenges of variable-focus,
                  wide-field-of-view, and high-dynamic-range imaging.
                </td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>09:00-09:30 am</td>
                <td>
                  <a href="https://people.engr.tamu.edu/nimak/index.html">
                    Nima Kalantari</a
                  >
                </td>
                <td style="border: none; max-width: 650px">
                  <b>Reconstructing 3D Scenes from Sparse Images</b>
                  <br />
                  Reconstructing the visual appearance of scenes has a wide
                  range of applications, including virtual/augmented reality,
                  e-commerce, and video conferencing. In recent years, the field
                  of novel view synthesis has seen significant progress with the
                  introduction of approaches like neural radiance fields.
                  However, accurately reconstructing 3D scenes still requires a
                  large number of input images, which is not feasible in most
                  practical scenarios. In this talk, I will discuss our recent
                  efforts to reconstruct 3D scenes from only a few or even a
                  single image. Specifically, I will first discuss our work on
                  novel view synthesis from a few images using 3D Gaussian
                  splatting. Then, I will talk about our approach to handle
                  view-dependent highlights in single-image view synthesis.
                </td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>09:30-10:00 am</td>
                <td>
                  <a href="https://federicotombari.github.io/"
                    >Federico Tombari</a
                  >
                </td>
                <td style="border: none; max-width: 650px">
                  <b
                    >3D scene understanding with neural representations for
                    Augmented Reality</b
                  >
                  <br />
                  Neural representations have shown tremendous progress and
                  represent a promising tool for novel applications in the space
                  of Augmented and Mixed Reality. In this talk I will give an
                  overview on the use of neural representations for AR/XR
                  applications with a focus on 3D scene understanding, and for
                  common tasks such as novel view synthesis, 3D semantic
                  segmentation and 3D asset generation. For each of these three
                  tasks, I will first highlight some important practical
                  limitations of current neural representations. I will then
                  show solutions designed to overcome such limitations, which
                  include mobile novel view synthesis at high framerate, open
                  set 3D scene segmentation with radiance fields, and realistic
                  3D asset generation from text prompts.
                </td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>10:00-10:30 am</td>
                <td>
                  <a href="https://leixiao-ubc.github.io/">Lei Xiao</a>
                </td>
                <td style="border: none; max-width: 650px">
                  <b>Exploring Neural Rendering for Mixed Reality</b>
                  <br />
                  In the realm of Mixed Reality, the pursuit for
                  perceptually-realistic 3D reconstruction and rendering of
                  dynamic environments represents a significant research
                  challenge. This is a crucial step towards our ultimate
                  aspiration of passing the Visual Turing Test on headsets. In
                  this talk, we will share our experiences and learnings on this
                  subject.<br />
                  We will touch upon a variety of specific challenges we have
                  encountered, such as gaze-contingent rendering, real-time
                  supersampling, real-time passthrough view synthesis, online
                  video depth estimation, and dynamic object reconstruction.
                  Additionally, we will share our explorations in the creative
                  domain of 3D stylization, and our initial steps towards
                  text-driven realistic 3D editing.
                </td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>10:30-11:15 am</td>
                <td>Poster Spotlight + Break</td>
                <td>Location: Convention Center Arch, Exhibition Hall 4E (Posters 70-79)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>11:15-11:45 pm</td>
                <td>
                  <a
                    href="https://scholar.google.fr/citations?user=cLPaHcIAAAAJ&hl=en"
                    >Natalia Neverova</a
                  >
                </td>
                <td style="border: none; max-width: 650px">
                  <b>Generative AI for 3D content creation</b>
                  <br />
                  Scaling XR Metaverse applications will require development of
                  fast and performant models for immersive content creation,
                  capable of generating and editing individual 3D assets,
                  animated 3D characters and eventually whole 3D worlds. In this
                  presentation, we will talk about first foundation blocks that
                  we are building as a part of this journey, from generating
                  shapes and texturing to creating full 3D assets with PBR
                  materials, starting with textual descriptions and visuals.
                </td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>11:45-12:15 pm</td>
                <td>
                  <a href="https://noamaig.github.io/">Noam Aigerman</a>
                </td>
                <td style="border: none; max-width: 650px">
                  <b
                    >Manipulating, Deforming and Controlling 3D Objects with
                    Machine Learning</b
                  >
                  <br />
                  Production of 3D content relies on the ability to manipulate
                  3D objects by ‚Äúdeforming‚Äù them, i.e., moving around 3D points
                  on the object: each frame in an animation sequence is a
                  deformation of a base model; alternatively, generation of 3D
                  shapes often relies on ‚Äúsculpting‚Äù the object from other
                  shapes through deformation, or otherwise adding additional
                  details to an existing object. Thus, enabling neural networks
                  to directly deform 3D objects can automate and improve such
                  applications, making learning of deformations a
                  heavily-researched area. However, devising learning-based
                  methods to accurately and robustly produce deformations that
                  meet practical application needs is a challenging and unsolved
                  task, especially when considering less-explicit 3D
                  representations, such as NeRFs, SDFs and Gaussian Splats. This
                  talk aims to give an overview of the specific challenges that
                  need to be overcome for a practical framework for learning
                  deformations, as well as the recent directions my work has
                  taken to tackle them.
                </td>
              </tr>
              <tr style="border-bottom: 1px solid #ccc">
                <td>12:15-12:45 pm</td>
                <td>
                  <a href="https://dvl.in.tum.de/team/lealtaixe/"
                    >Laura Leal-Taixe</a
                  >
                </td>
                <td style="border: none; max-width: 650px">
                  <b>Efficient Annotations for the Trackers of Tomorrow</b>
                  <br />
                  Multi-object tracking is an essential task for mixed reality,
                  which aims at seamlessly merging the virtual and the real
                  world, and therefore needs to have a good understanding of the
                  dynamics of the real world. Tracking algorithms are thriving
                  on large-scale dataset training, but video annotation is very
                  time consuming. <br />There are surprisingly very few works
                  exploring how to efficiently label tracking datasets
                  comprehensively. In this work, we introduce SPAM, a tracking
                  data engine that provides high-quality labels with minimal
                  human intervention. SPAM is built around two key insights: i)
                  most tracking scenarios can be easily resolved. To take
                  advantage of this, we utilize a pre-trained model to generate
                  high-quality pseudo-labels, reserving human involvement for a
                  smaller subset of more difficult instances; ii) handling the
                  spatiotemporal dependencies of track annotations across time
                  can be elegantly and efficiently formulated through graphs.
                  Therefore, we use a unified graph formulation to address the
                  annotation of both detections and identity association for
                  tracks across time. Based on these insights, SPAM produces
                  high-quality annotations with a fraction of ground truth
                  labeling cost.
                </td>
              </tr>
            </table>
          </div>
        </div>
      </div>
    </section> -->

    <!-- Speakers Section -->
    <section id="speakers" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Speakers</h2>
            <!-- <h3 class="section-subheading text-muted">
              Lorem ipsum dolor sit amet consectetur.
            </h3> -->
          </div>
        </div>
        <div class="row">
          <div class="col-sm-4"></div>
          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/richard.jpg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Richard Newcombe (Keynote)</h4>
              <p class="text-muted">Vice President, Research Science
                <br>
                Meta Reality Labs Research</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://rapiderobot.bitbucket.io/"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
                <li>
                  <a
                    href="https://scholar.google.co.uk/citations?user=MhowvPkAAAAJ&hl=en"
                    ><i class="fa fa-google"></i
                  ></a>
                </li>
                <li>
                  <a href="https://www.linkedin.com/in/richard-newcombe-a094164"
                    ><i class="fa fa-linkedin"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>
        </div>

        <div class="row">
          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/anjul.jpg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Anjul Patney</h4>
              <p class="text-muted">NVIDIA</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://anjulpatney.com/"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
                <li>
                  <a
                    href="https://scholar.google.com/citations?user=RbUgwbwAAAAJ&hl=en"
                    ><i class="fa fa-google"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>
          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/rana.jpg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Rana Hanocka</h4>
              <p class="text-muted">University of Chicago</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://people.cs.uchicago.edu/~ranahanocka/"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
                <li>
                  <a href="https://twitter.com/RanaHanocka"
                    ><i class="fa fa-twitter"></i
                  ></a>
                </li>
                <li>
                  <a
                    href="https://scholar.google.com/citations?user=3Bk5C9EAAAAJ&hl=en"
                    ><i class="fa fa-google"></i
                  ></a>
                </li>
                <li>
                  <a href="https://www.linkedin.com/in/ranahanocka/"
                    ><i class="fa fa-linkedin"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>

          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/laura.jpg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Laura Leal-Taix√©</h4>
              <p class="text-muted">NVIDIA, Technical University of Munich</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://dvl.in.tum.de/team/lealtaixe/"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
                <li>
                  <a href="https://twitter.com/lealtaixe?lang=en"
                    ><i class="fa fa-twitter"></i
                  ></a>
                </li>
                <li>
                  <a
                    href="https://scholar.google.es/citations?user=tT2TC-UAAAAJ"
                    ><i class="fa fa-google"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- <div class="row">
          <div class="col-lg-8 col-lg-offset-2 text-center">
            <p class="large text-muted">
              Lorem ipsum dolor sit amet, consectetur adipisicing elit. Aut
              eaque, laboriosam veritatis, quos non quis ad perspiciatis, totam
              corporis ea, alias ut unde.
            </p>
          </div>
        </div> -->
      </div>
    </section>

    <!-- Call for papers Section -->
    <section id="call_for_papers">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Call for Papers</h2>
          </div>
          <div class="col-lg-12 text-left">
            <div>
              <p><b>Important Dates</b></p>
              <ul>
                <li>Paper submission deadline: March 28, 2025</li>
                <li>Notification to authors: April 14, 2025</li>
                <li>Camera-ready deadline: April 24, 2025 (after this date, no more updates to the paper will be accepted)</li>
              </ul>
              <p><s>Papers submitted to the workshop will appear in the proceedings of the CVPR workshops in 2025. </s></p>
              <p><b>Announcement</b></p>
              <p>Only two weeks before our workshop submission deadline, CVPR Workshop Chairs unexpectedly communicated us a March 31 deadline for proceedings submission, leaving us only 48 hours for the review process. Despite our efforts, we were unable to extend this deadline with them.
                Rather than compromise on review quality, we've decided <b>not to submit accepted papers to the CVPR Workshop proceedings</b>. Our priority is to provide the authors with high-quality feedback, select the best papers, and ensure they are highlighted on the workshop website. Other workshop organizers we know are taking the same approach.
                Thank you for your understanding.</p>
            </div>
            <br>
            <div>
              <p><b>Topics of Interest</b></p>
              <p>The CV4MR 2025 workshop will highlight frontiers of innovation in turning wearable computers, sensors and displays into augmentations of human capability for productivity, life improvement or recreation.
                Since this topic is inherently interdisciplinary, we encourage authors to submit works in AI, Computer Vision, Image Processing or Computational Photography that they think are applicable to advancing this field.</p>
              <p>Authors are highly encouraged to motivate their applications for Mixed Reality in the submissions.</p>
              <p>Here is a non-exhaustive list of topics we encourage submissions on:</p>
              <ul>
                <li>Innovations in Real-Time passthrough
                  <ul>
                    <li>View Synthesis</li>
                    <li>Image and Audio Stylization</li>
                  </ul>
                </li>

                <li>3D Scene recovery from ego sensors
                  <ul>
                    <li>Depth Estimation</li>
                    <li>3D capture, reconstruction and rendering for virtual objects</li>
                    <li>SLAM and tracking</li>
                  </ul>
                </li>

                <li>Scene and Human understanding</li>

                <li>AI Agents for human assistance
                  <ul>
                    <li>Scenegraph-modifying or task agents</li>
                    <li>Humanoid / conversational agents</li>
                  </ul>
                </li>

                <li>AI for User Interaction and Spatial Design</li>

                <li>Innovations in AI-based graphics for Mixed Reality</li>

                <li>We also encourage submission on novel Applications of Mixed Reality in areas such as Healthcare, Manufacturing, etc.</li>
              </ul>
            </div>
            <br>
            <div>
              <p><b>Best Workshop Paper Award</b></p>
              <p>We are pleased to announce a CV4MR Best Workshop Paper Award (with a Meta Quest 3S prize sponsored by Meta), to be selected from the accepted papers.</p>
            </div>
            <br>
            <div>
              <p><b>Submission Guidelines:</b></p>
              <ul>
                <li>
                  We invite submissions of max 8 pages (excluding references),
                  and 4-page (excluding references) extended abstracts as well.
                </li>
                <li>
                  Submitted manuscript should follow the
                  <a href="https://github.com/cvpr-org/author-kit/releases">CVPR 2025 paper template</a>.
                </li>
                <li>
                  The review process is double-blind and does not involve a rebuttal phase. If you have other media to attach (videos etc), please feel
                  free to add anonymized links.
                </li>
                <li>
                  Submissions will be rejected without review if they:
                  <ul>
                    1. Contain more than 8 pages (excluding references).
                  </ul>
                  <ul>
                    2. Violate the double-blind policy.
                  </ul>
                  <ul>
                    3. Violate the dual-submission policy for papers with more
                    than 4 pages excluding references (to reiterate, we will not accept full papers already accepted into CVPR's papers track).
                  </ul>
                </li>
                <li>
                  Authors of all accepted submissions will be asked to present their work in a poster session (the guidelines for the posters are the same as at the main conference), in addition selected papers may be invited to deliver spotlight talks.
                </li>
                <li>
                  Authors submitting to the workshop will be asked to be added to the pool of reviewers.
                  For submissions with more than 2 authors, we will ask that at least 2 authors agree to be added to the workshop reviewer pool.
                  We will do our best to make the review workload reasonable, but for fairness, submissions by authors not completing reviews may be desk-rejected.
                </li>
              </ul>
            </div>
            <br>
            <div class="text-center">
              <a
                href="https://openreview.net/group?id=thecvf.com/CVPR/2025/Workshop/CV4MR"
                class="btn btn-xl"
                >Submissions (OpenReview)</a
              >
            </div>
            <br>
            <div>
              <p><b>Reviewing for CV4MR 2025</b></p>
              <p>Reviewers are the backbone for the integrity of knowledge in our workshop.
                For those interested in being added to the reviewer pool, please email <a href="mailto:someone@example.com">cv4mr@googlegroups.com</a> with the subject ‚ÄúReviewer Pool Participation‚Äù, some information about you, and your resume attached.
                </p>
            </div>
          </div>
        </div>
        <!-- <div class="row text-center">
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-shopping-cart fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">E-Commerce</h4>
            <p class="text-muted">
              Lorem ipsum dolor sit amet, consectetur adipisicing elit. Minima
              maxime quam architecto quo inventore harum ex magni, dicta
              impedit.
            </p>
          </div>
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-laptop fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Responsive Design</h4>
            <p class="text-muted">
              Lorem ipsum dolor sit amet, consectetur adipisicing elit. Minima
              maxime quam architecto quo inventore harum ex magni, dicta
              impedit.
            </p>
          </div>
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-lock fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Web Security</h4>
            <p class="text-muted">
              Lorem ipsum dolor sit amet, consectetur adipisicing elit. Minima
              maxime quam architecto quo inventore harum ex magni, dicta
              impedit.
            </p>
          </div>
        </div> -->
      </div>
    </section>

    <!-- Organizers Section -->
    <section id="organizers" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Organizers</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/rakesh.jpeg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Rakesh Ranjan</h4>
              <p class="text-muted">Meta</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://www.linkedin.com/in/rakesh-r-3848538/"
                    ><i class="fa fa-linkedin"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>
          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/omer2.png"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Omer Shapira</h4>
              <p class="text-muted">NVIDIA</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://omershapira.com/"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>

          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/margarita.png"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Margarita Grinvald</h4>
              <p class="text-muted">Meta</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://margaritagrinvald.com"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
                <li>
                  <a
                    href="https://scholar.google.com/citations?user=cEGl2uYAAAAJ"
                    ><i class="fa fa-google"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>

          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/ramya2.jpg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Ramya Akula</h4>
              <p class="text-muted">Meta</p>
            </div>
          </div>

          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/vikas.jpg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Vikas Chandra</h4>
              <p class="text-muted">Meta</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://v-chandra.github.io/"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
                <li>
                  <a href="https://twitter.com/vikasc"
                    ><i class="fa fa-twitter"></i
                  ></a>
                </li>
                <li>
                  <a
                    href="https://scholar.google.com/citations?user=p-h_BvcAAAAJ&hl=en"
                    ><i class="fa fa-google"></i
                  ></a>
                </li>
                <li>
                  <a href="https://www.linkedin.com/in/vchandra/"
                    ><i class="fa fa-linkedin"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>

          <div class="col-sm-4">
            <div class="team-member">
              <img
                src="img/team/andrea.jpg"
                class="img-responsive img-circle"
                alt=""
              />
              <h4>Andrea Colaco</h4>
              <p class="text-muted">Google</p>
              <ul class="list-inline social-buttons">
                <li>
                  <a href="https://andreacolaco.info/"
                    ><i class="fa fa-home"></i
                  ></a>
                </li>
                <li>
                  <a
                    href="https://scholar.google.com/citations?user=7pOIn7gAAAAJ&hl=en"
                    ><i class="fa fa-google"></i
                  ></a>
                </li>
                <li>
                  <a href="https://www.linkedin.com/in/andrea-colaco-612bb7a/"
                    ><i class="fa fa-linkedin"></i
                  ></a>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="contact">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Contact Us</h2>
            <h3 class="section-subheading text-primary">
              cv4mr@googlegroups.com
            </h3>
          </div>
        </div>
      </div>
    </section>

    <footer>
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <span class="copyright">Copyright &copy; CV4MR 2025</span>
          </div>
          <div class="col-md-4">
            <ul class="list-inline quicklinks">
              <li>Contact: cv4mr@googlegroups.com</li>
            </ul>
          </div>
        </div>
      </div>
    </footer>

    <!-- Portfolio Modals -->
    <!-- Use the modals below to showcase details about your portfolio projects! -->

    <!-- Portfolio Modal 1 -->
    <div
      class="portfolio-modal modal fade"
      id="portfolioModal1"
      tabindex="-1"
      role="dialog"
      aria-hidden="true"
    >
      <div class="modal-content">
        <div class="close-modal" data-dismiss="modal">
          <div class="lr">
            <div class="rl"></div>
          </div>
        </div>
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              <div class="modal-body">
                <!-- Project Details Go Here -->
                <h2>Project Name</h2>
                <p class="item-intro text-muted">
                  Lorem ipsum dolor sit amet consectetur.
                </p>
                <img
                  class="img-responsive"
                  src="img/portfolio/roundicons-free.png"
                  alt=""
                />
                <p>
                  Use this area to describe your project. Lorem ipsum dolor sit
                  amet, consectetur adipisicing elit. Est blanditiis dolorem
                  culpa incidunt minus dignissimos deserunt repellat aperiam
                  quasi sunt officia expedita beatae cupiditate, maiores
                  repudiandae, nostrum, reiciendis facere nemo!
                </p>
                <p>
                  <strong
                    >Want these icons in this portfolio item sample?</strong
                  >You can download 60 of them for free, courtesy of
                  <a
                    href="https://getdpd.com/cart/hoplink/18076?referrer=bvbo4kax5k8ogc"
                    >RoundIcons.com</a
                  >, or you can purchase the 1500 icon set
                  <a
                    href="https://getdpd.com/cart/hoplink/18076?referrer=bvbo4kax5k8ogc"
                    >here</a
                  >.
                </p>
                <ul class="list-inline">
                  <li>Date: July 2014</li>
                  <li>Client: Round Icons</li>
                  <li>Category: Graphic Design</li>
                </ul>
                <button
                  type="button"
                  class="btn btn-primary"
                  data-dismiss="modal"
                >
                  <i class="fa fa-times"></i> Close Project
                </button>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Portfolio Modal 2 -->
    <div
      class="portfolio-modal modal fade"
      id="portfolioModal2"
      tabindex="-1"
      role="dialog"
      aria-hidden="true"
    >
      <div class="modal-content">
        <div class="close-modal" data-dismiss="modal">
          <div class="lr">
            <div class="rl"></div>
          </div>
        </div>
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              <div class="modal-body">
                <h2>Project Heading</h2>
                <p class="item-intro text-muted">
                  Lorem ipsum dolor sit amet consectetur.
                </p>
                <img
                  class="img-responsive img-centered"
                  src="img/portfolio/startup-framework-preview.png"
                  alt=""
                />
                <p>
                  <a href="http://designmodo.com/startup/?u=787"
                    >Startup Framework</a
                  >
                  is a website builder for professionals. Startup Framework
                  contains components and complex blocks (PSD+HTML Bootstrap
                  themes and templates) which can easily be integrated into
                  almost any design. All of these components are made in the
                  same style, and can easily be integrated into projects,
                  allowing you to create hundreds of solutions for your future
                  projects.
                </p>
                <p>
                  You can preview Startup Framework
                  <a href="http://designmodo.com/startup/?u=787">here</a>.
                </p>
                <button
                  type="button"
                  class="btn btn-primary"
                  data-dismiss="modal"
                >
                  <i class="fa fa-times"></i> Close Project
                </button>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Portfolio Modal 3 -->
    <div
      class="portfolio-modal modal fade"
      id="portfolioModal3"
      tabindex="-1"
      role="dialog"
      aria-hidden="true"
    >
      <div class="modal-content">
        <div class="close-modal" data-dismiss="modal">
          <div class="lr">
            <div class="rl"></div>
          </div>
        </div>
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              <div class="modal-body">
                <!-- Project Details Go Here -->
                <h2>Project Name</h2>
                <p class="item-intro text-muted">
                  Lorem ipsum dolor sit amet consectetur.
                </p>
                <img
                  class="img-responsive img-centered"
                  src="img/portfolio/treehouse-preview.png"
                  alt=""
                />
                <p>
                  Treehouse is a free PSD web template built by
                  <a href="https://www.behance.net/MathavanJaya"
                    >Mathavan Jaya</a
                  >. This is bright and spacious design perfect for people or
                  startup companies looking to showcase their apps or other
                  projects.
                </p>
                <p>
                  You can download the PSD template in this portfolio sample
                  item at
                  <a
                    href="http://freebiesxpress.com/gallery/treehouse-free-psd-web-template/"
                    >FreebiesXpress.com</a
                  >.
                </p>
                <button
                  type="button"
                  class="btn btn-primary"
                  data-dismiss="modal"
                >
                  <i class="fa fa-times"></i> Close Project
                </button>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Portfolio Modal 4 -->
    <div
      class="portfolio-modal modal fade"
      id="portfolioModal4"
      tabindex="-1"
      role="dialog"
      aria-hidden="true"
    >
      <div class="modal-content">
        <div class="close-modal" data-dismiss="modal">
          <div class="lr">
            <div class="rl"></div>
          </div>
        </div>
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              <div class="modal-body">
                <!-- Project Details Go Here -->
                <h2>Project Name</h2>
                <p class="item-intro text-muted">
                  Lorem ipsum dolor sit amet consectetur.
                </p>
                <img
                  class="img-responsive img-centered"
                  src="img/portfolio/golden-preview.png"
                  alt=""
                />
                <p>
                  Start Bootstrap's Agency theme is based on Golden, a free PSD
                  website template built by
                  <a href="https://www.behance.net/MathavanJaya"
                    >Mathavan Jaya</a
                  >. Golden is a modern and clean one page web template that was
                  made exclusively for Best PSD Freebies. This template has a
                  great portfolio, timeline, and meet your team sections that
                  can be easily modified to fit your needs.
                </p>
                <p>
                  You can download the PSD template in this portfolio sample
                  item at
                  <a
                    href="http://freebiesxpress.com/gallery/golden-free-one-page-web-template/"
                    >FreebiesXpress.com</a
                  >.
                </p>
                <button
                  type="button"
                  class="btn btn-primary"
                  data-dismiss="modal"
                >
                  <i class="fa fa-times"></i> Close Project
                </button>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Portfolio Modal 5 -->
    <div
      class="portfolio-modal modal fade"
      id="portfolioModal5"
      tabindex="-1"
      role="dialog"
      aria-hidden="true"
    >
      <div class="modal-content">
        <div class="close-modal" data-dismiss="modal">
          <div class="lr">
            <div class="rl"></div>
          </div>
        </div>
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              <div class="modal-body">
                <!-- Project Details Go Here -->
                <h2>Project Name</h2>
                <p class="item-intro text-muted">
                  Lorem ipsum dolor sit amet consectetur.
                </p>
                <img
                  class="img-responsive img-centered"
                  src="img/portfolio/escape-preview.png"
                  alt=""
                />
                <p>
                  Escape is a free PSD web template built by
                  <a href="https://www.behance.net/MathavanJaya"
                    >Mathavan Jaya</a
                  >. Escape is a one page web template that was designed with
                  agencies in mind. This template is ideal for those looking for
                  a simple one page solution to describe your business and offer
                  your services.
                </p>
                <p>
                  You can download the PSD template in this portfolio sample
                  item at
                  <a
                    href="http://freebiesxpress.com/gallery/escape-one-page-psd-web-template/"
                    >FreebiesXpress.com</a
                  >.
                </p>
                <button
                  type="button"
                  class="btn btn-primary"
                  data-dismiss="modal"
                >
                  <i class="fa fa-times"></i> Close Project
                </button>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Portfolio Modal 6 -->
    <div
      class="portfolio-modal modal fade"
      id="portfolioModal6"
      tabindex="-1"
      role="dialog"
      aria-hidden="true"
    >
      <div class="modal-content">
        <div class="close-modal" data-dismiss="modal">
          <div class="lr">
            <div class="rl"></div>
          </div>
        </div>
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              <div class="modal-body">
                <!-- Project Details Go Here -->
                <h2>Project Name</h2>
                <p class="item-intro text-muted">
                  Lorem ipsum dolor sit amet consectetur.
                </p>
                <img
                  class="img-responsive img-centered"
                  src="img/portfolio/dreams-preview.png"
                  alt=""
                />
                <p>
                  Dreams is a free PSD web template built by
                  <a href="https://www.behance.net/MathavanJaya"
                    >Mathavan Jaya</a
                  >. Dreams is a modern one page web template designed for
                  almost any purpose. It‚Äôs a beautiful template that‚Äôs designed
                  with the Bootstrap framework in mind.
                </p>
                <p>
                  You can download the PSD template in this portfolio sample
                  item at
                  <a
                    href="http://freebiesxpress.com/gallery/dreams-free-one-page-web-template/"
                    >FreebiesXpress.com</a
                  >.
                </p>
                <button
                  type="button"
                  class="btn btn-primary"
                  data-dismiss="modal"
                >
                  <i class="fa fa-times"></i> Close Project
                </button>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>
  </body>
</html>
